{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available cuda: False\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optimpwd\n",
    "#import torch.utils.data as data\n",
    "#import torchvision.transforms as transforms\n",
    "#import torchvision.datasets as datasets\n",
    "import load_data\n",
    "#from tensorboardX import SummaryWriter\n",
    "from config import Config\n",
    "from model import _G,_D,Train\n",
    "import numpy as np\n",
    "#from PIL import Image\n",
    "#import torchvision.utils as vutils\n",
    "import plotting\n",
    "\n",
    "opt = Config()\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = opt.gpu_id\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Available cuda:\", use_cuda)\n",
    "#writer = SummaryWriter(log_dir=opt.logs)\n",
    "\n",
    "# Random seed\n",
    "if opt.seed is None:\n",
    "    opt.seed = random.randint(1, 10000)\n",
    "random.seed(opt.seed)\n",
    "np.random.seed(opt.seed)\n",
    "torch.manual_seed(opt.seed)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed_all(opt.seed)\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not os.path.isdir(opt.save_img):\n",
    "        os.makedirs(opt.save_img)\n",
    "    #if not os.path.isdir(opt.logs):\n",
    "    #    os.makedirs(opt.logs)\n",
    "    if not os.path.isdir(opt.data_dir):\n",
    "        os.makedirs(opt.data_dir)\n",
    "\n",
    "    # Data\n",
    "    trainx, trainy = load_data.load(opt.data_dir, subset='train')\n",
    "    trainx_unl = trainx.copy()\n",
    "    trainx_unl2 = trainx.copy()\n",
    "    testx, testy = load_data.load(opt.data_dir, subset='test')\n",
    "    nr_batches_train = int(trainx.shape[0]/opt.train_batch_size)\n",
    "    nr_batches_test = int(testx.shape[0]/opt.test_batch_size)\n",
    "    print(\"training batches:\",nr_batches_train,\"\\ntest batches:\",nr_batches_test)\n",
    "    \n",
    "    # Model\n",
    "    G = _G()\n",
    "    D = _D(num_classes=opt.num_classes)\n",
    "    if use_cuda:\n",
    "        D = torch.nn.DataParallel(D).cuda()\n",
    "        G = torch.nn.DataParallel(G).cuda()\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "    D.apply(weights_init)\n",
    "    G.apply(weights_init)\n",
    "    print('    G params: %.2fM,D params: %.2fM' % (sum(p.numel() for p in G.parameters())/1000000.0,sum(p.numel() for p in D.parameters())/1000000.0))\n",
    "    \n",
    "    optimizerD = optim.Adam(D.parameters(), lr=opt.lr, betas=(0.5, 0.999))\n",
    "    optimizerG = optim.Adam(G.parameters(), lr=opt.lr, betas=(0.5, 0.999))\n",
    "    T = Train(G,D,optimizerG,optimizerD)\n",
    "    \n",
    "    ids = np.arange(trainx.shape[0])\n",
    "    np.random.shuffle(ids)\n",
    "    trainx = trainx[ids]\n",
    "    trainy = trainy[ids]\n",
    "    txs,tys = [],[]\n",
    "    for i in range(opt.num_classes):\n",
    "        txs.append(trainx[trainy==i][:opt.count])\n",
    "        tys.append(trainy[trainy==i][:opt.count])\n",
    "    txs = np.concatenate(txs, axis=0)\n",
    "    tys = np.concatenate(tys, axis=0)\n",
    "    \n",
    "    # Training Loop\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(opt.epochs):\n",
    "        print(\"Start with epoch\",epoch)\n",
    "        start_time: float = time.time()\n",
    "        lr = np.cast[float](opt.lr * np.minimum(3. - epoch/400., 1.))\n",
    "        trainx = []\n",
    "        trainy = []\n",
    "        for t in range(int(np.ceil(trainx_unl.shape[0]/float(txs.shape[0])))):\n",
    "            ids = np.arange(txs.shape[0])\n",
    "            np.random.shuffle(ids)\n",
    "            trainx.append(txs[ids])\n",
    "            trainy.append(tys[ids])\n",
    "        trainx = np.concatenate(trainx, axis=0)\n",
    "        trainy = np.concatenate(trainy, axis=0)\n",
    "        ids1 = np.arange(trainx_unl.shape[0])\n",
    "        ids2 = np.arange(trainx_unl2.shape[0])\n",
    "\n",
    "        trainx_unl = trainx_unl[ids1]\n",
    "        trainx_unl2 = trainx_unl2[ids2]\n",
    "\n",
    "        total_lab,total_unlab,total_train_acc,total_gen = 0.0,0.0,0.0,0.0\n",
    "        for i in range(nr_batches_train):\n",
    "            print(\"Start Training Batch\",i)\n",
    "            start = i*opt.train_batch_size\n",
    "            end = (i+1)*opt.train_batch_size\n",
    "            x_lab = torch.from_numpy(trainx[start:end])\n",
    "            y = torch.from_numpy(trainy[start:end]).long()\n",
    "            x_unlab = torch.from_numpy(trainx_unl[start:end])\n",
    "            \n",
    "            #train Disc\n",
    "            print(\"Training of Discriminator...\")\n",
    "            loss_lab,loss_unlab,train_acc = T.discriminator_training(x_lab,y,x_unlab)\n",
    "            total_lab += loss_lab\n",
    "            total_unlab += loss_unlab\n",
    "            total_train_acc += train_acc\n",
    "            \n",
    "            #train Gen\n",
    "            print(\"Training of Generator...\")\n",
    "            x_unlab = torch.from_numpy(trainx_unl2[start:end])\n",
    "            loss_gen = T.generator_training(x_unlab)\n",
    "            if loss_gen>1 and epoch >1:\n",
    "                loss_gen = T.generator_training(x_unlab)\n",
    "            total_gen +=loss_gen\n",
    "\n",
    "        T.update_learning_rate(lr)\n",
    "        total_lab /= nr_batches_train\n",
    "        total_unlab /= nr_batches_train\n",
    "        total_train_acc /= nr_batches_train\n",
    "        total_gen /= nr_batches_train\n",
    "\n",
    "        # Test\n",
    "        test_acc = 0.0\n",
    "        for i in range(nr_batches_test):\n",
    "            print(\"Start Test Batch\",i)\n",
    "            start = i*opt.test_batch_size\n",
    "            end = (i+1)*opt.test_batch_size\n",
    "            x =  torch.from_numpy(testx[start:end])\n",
    "            y =  torch.from_numpy(testy[start:end]).long()\n",
    "            test_acc += T.test(x,y)\n",
    "        test_acc /= nr_batches_test\n",
    "        if test_acc >best_acc:\n",
    "            best_acc = test_acc\n",
    "        \n",
    "        # Save the generated images\n",
    "        print(\"Saving generated images...\")\n",
    "        if torch.cuda.is_available():\n",
    "            noise = T.noise.cuda()\n",
    "        else:\n",
    "            noise = T.noise\n",
    "        with torch.no_grad():\n",
    "            gen_data = T.G(noise) \n",
    "        plotting.save_png(gen_data,opt.save_img,epoch)\n",
    "\n",
    "        # Print final loss and accuracy\n",
    "        if (epoch+1)%(opt.fre_print)==0:\n",
    "            print(\"Iteration %d, loss_lab = %.4f, loss_unl = %.4f,loss_gen = %.4f, train acc = %.4f, test acc = %.4f,best acc = %.4f\" % (epoch,total_lab, total_unlab, total_gen,total_train_acc, test_acc,best_acc))        \n",
    "        print(\"Epoch time:\", time.time()-start_time)\n",
    "\n",
    "        #viso\n",
    "        #writer.add_scalar('train/loss_supervised',total_lab,epoch)\n",
    "        #writer.add_scalar('train/un_loss_supervised',total_unlab,epoch)\n",
    "        #writer.add_scalar('train/gen_loss',total_gen,epoch)\n",
    "        #writer.add_scalar('train/acc',total_train_acc,epoch)\n",
    "        #writer.add_scalar('test/acc',test_acc,epoch)\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname=m.__class__.__name__\n",
    "    if classname.find('Conv') != -1 or classname.find('ConvTranspose2d')!= -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.05)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.05)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Downloading cifar-10-python.tar.gz 47.8%"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1800\\217905245.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1800\\3621404089.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;31m# Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mtrainx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[0mtrainx_unl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mtrainx_unl2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Aileen\\OneDrive - TU Wien\\Dokumente\\GitHub\\applied_DL22\\load_data.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(data_dir, subset, download)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cifar-10-batches-py'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mdownload_and_extract_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0munpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'cifar-10-batches-py/data_batch_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Aileen\\OneDrive - TU Wien\\Dokumente\\GitHub\\applied_DL22\\load_data.py\u001b[0m in \u001b[0;36mdownload_and_extract_data\u001b[1;34m(data_dir, url)\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_progress\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mstatinfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Successfully downloaded'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatinfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mst_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bytes.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mtarfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r:gz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Aileen\\AppData\\Local\\Programs\\Python\\Python37\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    281\u001b[0m                 \u001b[0mblocknum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mreporthook\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m                     \u001b[0mreporthook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocknum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mread\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Aileen\\OneDrive - TU Wien\\Dokumente\\GitHub\\applied_DL22\\load_data.py\u001b[0m in \u001b[0;36m_progress\u001b[1;34m(count, block_size, total_size)\u001b[0m\n\u001b[0;32m     21\u001b[0m                             )\n\u001b[0;32m     22\u001b[0m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_progress\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mstatinfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Successfully downloaded'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatinfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mst_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bytes.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mflush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    486\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[1;31m# and give a timeout to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 488\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m                 \u001b[1;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m                 \u001b[1;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Aileen\\AppData\\Local\\Programs\\Python\\Python37\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Aileen\\AppData\\Local\\Programs\\Python\\Python37\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8rc1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f921f6e02e6df8a27b0286b4045ce39a6433c378481d17081335bd7d15ebd952"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
